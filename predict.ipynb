{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data):\n",
    "    # Convert string dates to datetime\n",
    "    data['created_date'] = pd.to_datetime(data['created_date'], format='%Y-%m-%d')\n",
    "    data['solved_at_date'] = pd.to_datetime(data['solved_at_date'], format='%Y-%m-%d')\n",
    "    data['estimated_installation_date'] = pd.to_datetime(data['estimated_installation_date'], format='%Y-%m-%d')\n",
    "    \n",
    "    # Create additional features\n",
    "    data['ticket_month'] = data['created_date'].dt.month\n",
    "    data['ticket_year'] = data['created_date'].dt.year\n",
    "    \n",
    "    # Extract device model from device_alias\n",
    "    data['device_model'] = data['device_alias']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze device failures\n",
    "def analyze_device_failures(data):\n",
    "    # Group data by device and determine if there are indicators of failures\n",
    "    # For this example, we'll consider tickets with 'fix' flags and longer resolution times as potential indicators\n",
    "    \n",
    "    # Define what constitutes a \"failure\" based on the data\n",
    "    # This is an assumption - adjust based on domain knowledge\n",
    "    failure_categories = [\n",
    "        'IMAGE CAPTURE',\n",
    "        'ELECTRONICS',\n",
    "        'MECHANICS',\n",
    "        'IMAGE QUALITY 3D',\n",
    "        'IMAGE QUALITY 2D'\n",
    "    ]\n",
    "    \n",
    "    data['is_failure'] = data['category_level3'].isin(failure_categories)\n",
    "    \n",
    "    # Group by device to get failure history\n",
    "    device_failures = data.groupby('product_key').agg({\n",
    "        'is_failure': 'sum',\n",
    "        'transaction_number': 'count',\n",
    "        'device_age': 'max',\n",
    "        'device_model': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    device_failures.rename(columns={\n",
    "        'is_failure': 'failure_count',\n",
    "        'transaction_number': 'ticket_count'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Calculate failure rate\n",
    "    device_failures['failure_rate'] = device_failures['failure_count'] / device_failures['ticket_count']\n",
    "    \n",
    "    return device_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time_to_failure(data, device_failures):\n",
    "    # Create a survival dataset\n",
    "    survival_data = device_failures.copy()\n",
    "    \n",
    "    # Add additional features that might be relevant for survival prediction\n",
    "    device_categories = data.groupby('product_key').agg({\n",
    "        'category_level1': lambda x: x.value_counts().index[0],\n",
    "        'category_level2': lambda x: x.value_counts().index[0],\n",
    "        'category_level3': lambda x: x.value_counts().index[0],\n",
    "        'record_type': lambda x: x.value_counts().index[0],\n",
    "        'oob_or_not': lambda x: x.value_counts().index[0]\n",
    "    }).reset_index()\n",
    "    \n",
    "    survival_data = pd.merge(survival_data, device_categories, on='product_key')\n",
    "    \n",
    "    # Create a binary indicator for whether the device has already failed\n",
    "    survival_data['has_failed'] = (survival_data['failure_count'] > 0).astype(int)\n",
    "    \n",
    "    # For devices that haven't failed, the \"time\" will be censored at their current age\n",
    "    survival_data['time'] = survival_data['device_age']\n",
    "    \n",
    "    # Fit a Cox Proportional Hazards model\n",
    "    cph = CoxPHFitter(penalizer=0.1)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    categorical_cols = ['device_model', 'category_level1', 'category_level2', 'category_level3', 'record_type', 'oob_or_not']\n",
    "    encoded_cols = pd.get_dummies(survival_data[categorical_cols], drop_first=True)\n",
    "    \n",
    "    # Combine with numerical features\n",
    "    numerical_cols = ['ticket_count', 'device_age']\n",
    "    model_data = pd.concat([survival_data[numerical_cols], encoded_cols], axis=1)\n",
    "    \n",
    "    # Add the target variables\n",
    "    model_data['duration'] = survival_data['time']\n",
    "    model_data['event'] = survival_data['has_failed']\n",
    "    \n",
    "    # Handle any missing or infinite values\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    # Fit the model\n",
    "    try:\n",
    "        cph.fit(model_data, duration_col='duration', event_col='event', fit_options={'step_size': 0.5, 'max_steps': 100})\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting Cox Proportional Hazards model: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Generate predictions\n",
    "    survival_data['hazard_ratio'] = cph.predict_partial_hazard(model_data)\n",
    "    survival_data['predicted_risk'] = 1 - np.exp(-survival_data['hazard_ratio'])\n",
    "    \n",
    "    # Calculate expected time to failure\n",
    "    baseline_time = survival_data[survival_data['has_failed'] == 1]['time'].mean()\n",
    "    if pd.isna(baseline_time) or baseline_time == 0:\n",
    "        baseline_time = 5  # Default value if no failure data is available\n",
    "        \n",
    "    survival_data['predicted_time_to_failure'] = baseline_time / survival_data['hazard_ratio']\n",
    "    \n",
    "    # For devices that have already failed, their predicted time should be 0\n",
    "    survival_data.loc[survival_data['has_failed'] == 1, 'predicted_time_to_failure'] = 0\n",
    "    \n",
    "    return survival_data, cph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict multiple tickets in next 90 days\n",
    "def predict_multiple_tickets(data):\n",
    "    # Create a feature to identify devices with multiple tickets\n",
    "    device_tickets = data.groupby(['product_key', 'ticket_month', 'ticket_year']).size().reset_index(name='monthly_tickets')\n",
    "    devices_with_multiple = device_tickets[device_tickets['monthly_tickets'] > 1]['product_key'].unique()\n",
    "    \n",
    "    # Create a target variable - 1 if device had multiple tickets in any month\n",
    "    data['had_multiple_tickets'] = data['product_key'].isin(devices_with_multiple).astype(int)\n",
    "    \n",
    "    # Aggregate data by device\n",
    "    device_features = data.groupby('product_key').agg({\n",
    "        'device_age': 'max',\n",
    "        'days_to_resolve': 'mean',\n",
    "        'had_multiple_tickets': 'max',\n",
    "        'device_model': 'first',\n",
    "        'transaction_number': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    device_features.rename(columns={'transaction_number': 'total_tickets'}, inplace=True)\n",
    "    \n",
    "    # Add category information\n",
    "    category_features = pd.get_dummies(data[['product_key', 'category_level1', 'category_level2', 'category_level3']], \n",
    "                                     columns=['category_level1', 'category_level2', 'category_level3'],\n",
    "                                     prefix=['cat1', 'cat2', 'cat3'])\n",
    "    \n",
    "    category_counts = category_features.groupby('product_key').sum().reset_index()\n",
    "    device_features = pd.merge(device_features, category_counts, on='product_key')\n",
    "    \n",
    "    # Split data for training\n",
    "    X = device_features.drop(['product_key', 'had_multiple_tickets', 'device_model'], axis=1)\n",
    "    y = device_features['had_multiple_tickets']\n",
    "    \n",
    "    # Handle any missing values\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    # Train a Random Forest model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create and train the model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on all devices\n",
    "    device_features['multiple_ticket_probability'] = rf_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Add a binary prediction (1 if probability > 0.5)\n",
    "    device_features['predicted_multiple_tickets'] = (device_features['multiple_ticket_probability'] > 0.5).astype(int)\n",
    "    \n",
    "    return device_features, rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_csv):\n",
    "    # Load data\n",
    "    data = load_and_prepare_data(data_csv)\n",
    "    \n",
    "    # Analyze device failures\n",
    "    device_failures = analyze_device_failures(data)\n",
    "    \n",
    "    # Predict time to failure\n",
    "    survival_results, survival_model = predict_time_to_failure(data, device_failures)\n",
    "    \n",
    "    # Predict multiple tickets\n",
    "    multiple_ticket_results, ticket_model = predict_multiple_tickets(data)\n",
    "    \n",
    "    # Combine results\n",
    "    final_results = pd.merge(survival_results, multiple_ticket_results[['product_key', 'multiple_ticket_probability', 'predicted_multiple_tickets']], \n",
    "                            on='product_key')\n",
    "    \n",
    "    # Return the full results and models\n",
    "    return final_results, survival_model, ticket_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions for new devices\n",
    "def predict_for_new_device(device_info, survival_model, ticket_model):\n",
    "    # Format the device information for prediction\n",
    "    # This would need to be adapted to match the format expected by the models\n",
    "    \n",
    "    # Make predictions\n",
    "    failure_prediction = survival_model.predict_expectation(device_info)\n",
    "    ticket_prediction = ticket_model.predict_proba(device_info)\n",
    "    \n",
    "    return {\n",
    "        'expected_time_to_failure': failure_prediction,\n",
    "        'multiple_ticket_probability': ticket_prediction\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "df = pd.read_csv('Cleaned_Merged_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_number</th>\n",
       "      <th>product_key</th>\n",
       "      <th>device_alias</th>\n",
       "      <th>fix_flag</th>\n",
       "      <th>record_type</th>\n",
       "      <th>oob_or_not</th>\n",
       "      <th>oob_status</th>\n",
       "      <th>created_date</th>\n",
       "      <th>solved_at_date</th>\n",
       "      <th>days_to_resolve</th>\n",
       "      <th>days_to_resolve_bucket</th>\n",
       "      <th>category_level1</th>\n",
       "      <th>category_level2</th>\n",
       "      <th>category_level3</th>\n",
       "      <th>category_level4</th>\n",
       "      <th>estimated_installation_date</th>\n",
       "      <th>device_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000277679</td>\n",
       "      <td>6466580-5200873</td>\n",
       "      <td>LUNAR HALO 3D</td>\n",
       "      <td>PS: FIRST-FIX</td>\n",
       "      <td>COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)</td>\n",
       "      <td>NOT OOB</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0 days</td>\n",
       "      <td>IMAGING SYSTEMS</td>\n",
       "      <td>FOUR DIMENSION</td>\n",
       "      <td>INSTALLATION</td>\n",
       "      <td>LICENSE ISSUE</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000277696</td>\n",
       "      <td>6464999-502537</td>\n",
       "      <td>OMEGA PRISM 3D 11X10</td>\n",
       "      <td>PS: FIRST-FIX</td>\n",
       "      <td>COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)</td>\n",
       "      <td>OOB</td>\n",
       "      <td>OUT OF BOX</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0 days</td>\n",
       "      <td>IMAGING SYSTEMS</td>\n",
       "      <td>LUNAR SPECTRUM</td>\n",
       "      <td>IMAGE CAPTURE</td>\n",
       "      <td>RCU NOT ACCESSIBLE</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8000277699</td>\n",
       "      <td>6464999-502325</td>\n",
       "      <td>OMEGA PRISM 3D 11X10</td>\n",
       "      <td>PS: FIRST-FIX</td>\n",
       "      <td>COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)</td>\n",
       "      <td>NOT OOB</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0 days</td>\n",
       "      <td>IMAGING SYSTEMS</td>\n",
       "      <td>FOUR DIMENSION</td>\n",
       "      <td>DATABASE</td>\n",
       "      <td>DATABASE RELOCATION ISSUE</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8000277708</td>\n",
       "      <td>6562297-550442</td>\n",
       "      <td>LUNAR HALO 3D</td>\n",
       "      <td>PS: FIRST-FIX</td>\n",
       "      <td>COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)</td>\n",
       "      <td>NOT OOB</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0 days</td>\n",
       "      <td>IMAGING SYSTEMS</td>\n",
       "      <td>LUNAR SPECTRUM</td>\n",
       "      <td>IMAGE CAPTURE</td>\n",
       "      <td>RCU NOT ACCESSIBLE</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8000277718</td>\n",
       "      <td>6431659-3630803</td>\n",
       "      <td>VORTEX NEXUS 3D</td>\n",
       "      <td>PS: FIRST-FIX</td>\n",
       "      <td>COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)</td>\n",
       "      <td>NOT OOB</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0 days</td>\n",
       "      <td>IMAGING SYSTEMS</td>\n",
       "      <td>FOUR DIMENSION</td>\n",
       "      <td>INSTALLATION</td>\n",
       "      <td>INSTALLATION / UNINSTALLATION SIDEXIS WORKSTATION</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_number      product_key          device_alias       fix_flag  \\\n",
       "0          8000277679  6466580-5200873         LUNAR HALO 3D  PS: FIRST-FIX   \n",
       "1          8000277696   6464999-502537  OMEGA PRISM 3D 11X10  PS: FIRST-FIX   \n",
       "2          8000277699   6464999-502325  OMEGA PRISM 3D 11X10  PS: FIRST-FIX   \n",
       "3          8000277708   6562297-550442         LUNAR HALO 3D  PS: FIRST-FIX   \n",
       "4          8000277718  6431659-3630803       VORTEX NEXUS 3D  PS: FIRST-FIX   \n",
       "\n",
       "                                       record_type oob_or_not  oob_status  \\\n",
       "0  COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)    NOT OOB     SERVICE   \n",
       "1  COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)        OOB  OUT OF BOX   \n",
       "2  COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)    NOT OOB     SERVICE   \n",
       "3  COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)    NOT OOB     SERVICE   \n",
       "4  COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)    NOT OOB     SERVICE   \n",
       "\n",
       "  created_date solved_at_date  days_to_resolve days_to_resolve_bucket  \\\n",
       "0   2019-01-02     2019-01-02              0.0               0.0 days   \n",
       "1   2019-01-02     2019-01-02              0.0               0.0 days   \n",
       "2   2019-01-02     2019-01-02              0.0               0.0 days   \n",
       "3   2019-01-02     2019-01-02              0.0               0.0 days   \n",
       "4   2019-01-02     2019-01-02              0.0               0.0 days   \n",
       "\n",
       "   category_level1 category_level2 category_level3  \\\n",
       "0  IMAGING SYSTEMS  FOUR DIMENSION    INSTALLATION   \n",
       "1  IMAGING SYSTEMS  LUNAR SPECTRUM   IMAGE CAPTURE   \n",
       "2  IMAGING SYSTEMS  FOUR DIMENSION        DATABASE   \n",
       "3  IMAGING SYSTEMS  LUNAR SPECTRUM   IMAGE CAPTURE   \n",
       "4  IMAGING SYSTEMS  FOUR DIMENSION    INSTALLATION   \n",
       "\n",
       "                                     category_level4  \\\n",
       "0                                      LICENSE ISSUE   \n",
       "1                                 RCU NOT ACCESSIBLE   \n",
       "2                          DATABASE RELOCATION ISSUE   \n",
       "3                                 RCU NOT ACCESSIBLE   \n",
       "4  INSTALLATION / UNINSTALLATION SIDEXIS WORKSTATION   \n",
       "\n",
       "  estimated_installation_date  device_age  \n",
       "0                  2019-01-03         5.0  \n",
       "1                  2018-12-31         5.0  \n",
       "2                  2023-01-13         1.0  \n",
       "3                  2018-04-17         5.0  \n",
       "4                  2017-08-17         6.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ticket_count'] = df.groupby('product_key')['transaction_number'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                 device_age  days_to_resolve  ticket_count\n",
      "device_age         1.000000        -0.063473      0.298579\n",
      "days_to_resolve   -0.063473         1.000000     -0.086678\n",
      "ticket_count       0.298579        -0.086678      1.000000\n",
      "Chi-square test for device_alias and category_level1:\n",
      "p-value: 3.2596402080313634e-42\n",
      "Chi-square test for device_alias and category_level2:\n",
      "p-value: 0.0\n",
      "Chi-square test for device_alias and category_level3:\n",
      "p-value: 0.0\n",
      "Chi-square test for device_alias and category_level4:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level1 and device_alias:\n",
      "p-value: 3.2596402080313634e-42\n",
      "Chi-square test for category_level1 and category_level2:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level1 and category_level3:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level1 and category_level4:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level2 and device_alias:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level2 and category_level1:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level2 and category_level3:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level2 and category_level4:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level3 and device_alias:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level3 and category_level1:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level3 and category_level2:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level3 and category_level4:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level4 and device_alias:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level4 and category_level1:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level4 and category_level2:\n",
      "p-value: 0.0\n",
      "Chi-square test for category_level4 and category_level3:\n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate correlation matrix for numerical variables\n",
    "numerical_cols = ['device_age', 'days_to_resolve', 'ticket_count']\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Step 2: Perform chi-square tests for categorical variables\n",
    "categorical_cols = ['device_alias', 'category_level1', 'category_level2', 'category_level3', 'category_level4']\n",
    "\n",
    "for col1 in categorical_cols:\n",
    "    for col2 in categorical_cols:\n",
    "        if col1 != col2:\n",
    "            contingency_table = pd.crosstab(df[col1], df[col2])\n",
    "            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "            print(f\"Chi-square test for {col1} and {col2}:\")\n",
    "            print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Inflation Factors:\n",
      "          Variable       VIF\n",
      "0            const  5.314273\n",
      "1       device_age  1.099264\n",
      "2  days_to_resolve  1.009149\n",
      "3     ticket_count  1.103121\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Calculate VIF for numerical predictors\n",
    "numerical_cols = ['device_age', 'days_to_resolve', 'ticket_count']\n",
    "\n",
    "# Clean the data\n",
    "X = df[numerical_cols].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Check if there's enough data left after cleaning\n",
    "if X.shape[0] > 0:\n",
    "    X = add_constant(X)  # Add constant term to the predictors\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    print(\"Variance Inflation Factors:\")\n",
    "    print(vif_data)\n",
    "else:\n",
    "    print(\"Not enough valid data to calculate VIF after removing inf and NaN values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Correlation Matrix:\n",
    "- There's a moderate positive correlation (0.298579) between device_age and ticket_count, suggesting that older devices tend to have more tickets.\n",
    "\n",
    "- A very weak negative correlation (-0.063473) exists between device_age and days_to_resolve, indicating that older devices might have slightly shorter resolution times.\n",
    "\n",
    "- There's a weak negative correlation (-0.086678) between ticket_count and days_to_resolve, suggesting that devices with more tickets might have slightly faster resolution times.\n",
    "\n",
    "2. Chi-square tests:\n",
    "\n",
    "- All p-values are extremely low (< 0.05), indicating strong statistical dependencies between the categorical variables (device_alias, category_level1, category_level2, and category_level3).\n",
    "\n",
    "- This suggests that these categorical variables are not independent of each other, which could lead to multicollinearity issues in your model.\n",
    "\n",
    "\n",
    "3. Variance Inflation Factors (VIF):\n",
    "\n",
    "- The VIF values for device_age (1.099264), days_to_resolve (1.009149), and ticket_count (1.103121) are all close to 1, indicating low multicollinearity among these numerical predictors.\n",
    "\n",
    "- The constant term has a higher VIF (5.314273), but this is not unusual and doesn't affect the interpretation of other predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average days to resolve by record type: record_type\n",
      "COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)                  2.575824\n",
      "COMPLAINT (POTENTIAL SAFETY RELEVANT / POTENTIAL REPORTABLE)    40.875000\n",
      "INQUIRY                                                          3.154464\n",
      "REPAIR AND SERVICE                                               2.273264\n",
      "Name: days_to_resolve, dtype: float64\n",
      "T-test results for days to resolve: -5.585859879800117 2.3377521059685676e-08\n",
      "Average device age by record type: record_type\n",
      "COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)                 5.602376\n",
      "COMPLAINT (POTENTIAL SAFETY RELEVANT / POTENTIAL REPORTABLE)    5.312500\n",
      "INQUIRY                                                         5.576106\n",
      "REPAIR AND SERVICE                                              4.825497\n",
      "Name: device_age, dtype: float64\n",
      "T-test results for device age: 0.8468749935950545 0.39706893008781663\n",
      "Correlation between device age and days to resolve: -0.06347349601697987 1.6688488146764874e-49\n",
      "Linear regression results: -0.2052961828946381 3.8347824443237832\n",
      "Multi-factor analysis results: [38.23858412  0.57314866 -0.46494816 -0.2090255 ] 3.746863863632723\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_record_type_and_days_to_resolve(data):\n",
    "    # Calculate average days_to_resolve for each record_type\n",
    "    avg_days = data.groupby('record_type')['days_to_resolve'].mean()\n",
    "    \n",
    "    # Perform t-test\n",
    "    complaint_days = data[data['record_type'] == 'COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)']['days_to_resolve']\n",
    "    inquiry_days = data[data['record_type'] == 'INQUIRY']['days_to_resolve']\n",
    "    t_stat, p_value = stats.ttest_ind(complaint_days, inquiry_days)\n",
    "    \n",
    "    return avg_days, t_stat, p_value\n",
    "\n",
    "def analyze_record_type_and_device_age(data):\n",
    "    # Calculate average device_age for each record_type\n",
    "    avg_age = data.groupby('record_type')['device_age'].mean()\n",
    "    \n",
    "    # Perform t-test\n",
    "    complaint_age = data[data['record_type'] == 'COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE)']['device_age']\n",
    "    inquiry_age = data[data['record_type'] == 'INQUIRY']['device_age']\n",
    "    t_stat, p_value = stats.ttest_ind(complaint_age, inquiry_age)\n",
    "    \n",
    "    return avg_age, t_stat, p_value\n",
    "\n",
    "def analyze_device_age_and_days_to_resolve(data):\n",
    "    # Calculate Pearson correlation\n",
    "    correlation, p_value = stats.pearsonr(data['device_age'], data['days_to_resolve'])\n",
    "    \n",
    "    # Perform linear regression\n",
    "    X = data['device_age'].values.reshape(-1, 1)\n",
    "    y = data['days_to_resolve'].values\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    \n",
    "    return correlation, p_value, reg.coef_[0], reg.intercept_\n",
    "\n",
    "def multi_factor_analysis(data):\n",
    "    X = pd.get_dummies(data['record_type'], drop_first=True)\n",
    "    X['device_age'] = data['device_age']\n",
    "    y = data['days_to_resolve']\n",
    "    \n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    return reg.coef_, reg.intercept_\n",
    "\n",
    "def create_visualizations(data):\n",
    "    # Box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='record_type', y='days_to_resolve', data=data)\n",
    "    plt.title('Distribution of Days to Resolve by Record Type')\n",
    "    plt.savefig('boxplot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='device_age', y='days_to_resolve', hue='record_type', data=data)\n",
    "    plt.title('Device Age vs Days to Resolve')\n",
    "    plt.savefig('scatterplot.png')\n",
    "    plt.close()\n",
    "\n",
    "def clean_data(data):\n",
    "    # Replace inf with NaN\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Main function to run all analyses\n",
    "def run_analysis(data):\n",
    "    # Clean the data\n",
    "    data = clean_data(data)\n",
    "    \n",
    "    avg_days, t_stat_days, p_value_days = analyze_record_type_and_days_to_resolve(data)\n",
    "    avg_age, t_stat_age, p_value_age = analyze_record_type_and_device_age(data)\n",
    "    corr, p_value_corr, slope, intercept = analyze_device_age_and_days_to_resolve(data)\n",
    "    multi_coef, multi_intercept = multi_factor_analysis(data)\n",
    "    create_visualizations(data)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Average days to resolve by record type:\", avg_days)\n",
    "    print(\"T-test results for days to resolve:\", t_stat_days, p_value_days)\n",
    "    print(\"Average device age by record type:\", avg_age)\n",
    "    print(\"T-test results for device age:\", t_stat_age, p_value_age)\n",
    "    print(\"Correlation between device age and days to resolve:\", corr, p_value_corr)\n",
    "    print(\"Linear regression results:\", slope, intercept)\n",
    "    print(\"Multi-factor analysis results:\", multi_coef, multi_intercept)\n",
    "\n",
    "# Usage\n",
    "data = pd.read_csv('Cleaned_Merged_data.csv')\n",
    "run_analysis(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Days to Resolve by Record Type:\n",
    "\n",
    "- COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE): 2.58 days\n",
    "\n",
    "- COMPLAINT (POTENTIAL SAFETY RELEVANT / POTENTIAL REPORTABLE): 40.88 days\n",
    "\n",
    "- INQUIRY: 3.15 days\n",
    "\n",
    "- REPAIR AND SERVICE: 2.27 days\n",
    "\n",
    "The t-test results (t-statistic: -5.59, p-value: 2.34e-08) indicate a statistically significant difference in resolution times between record types.\n",
    "\n",
    "\n",
    "2. Device Age by Record Type:\n",
    "\n",
    "- COMPLAINT (NO SAFETY IMPACT AND NOT REPORTABLE): 5.60 years\n",
    "\n",
    "- COMPLAINT (POTENTIAL SAFETY RELEVANT / POTENTIAL REPORTABLE): 5.31 years\n",
    "\n",
    "- INQUIRY: 5.58 years\n",
    "\n",
    "- REPAIR AND SERVICE: 4.83 years\n",
    "\n",
    "The t-test results (t-statistic: 0.85, p-value: 0.40) suggest no statistically significant difference in device age between record types.\n",
    "\n",
    "3. Correlation between Device Age and Days to Resolve:\n",
    "\n",
    "- Correlation coefficient: -0.063\n",
    "\n",
    "- P-value: 1.67e-49\n",
    "\n",
    "There is a very weak negative correlation between device age and days to resolve, which is statistically significant due to the extremely low p-value.\n",
    "\n",
    "4. Linear Regression:\n",
    "\n",
    "- Slope: -0.21\n",
    "\n",
    "- Intercept: 3.83\n",
    "\n",
    "This suggests that for each year increase in device age, the days to resolve decreases by 0.21 days on average.\n",
    "\n",
    "\n",
    "5. Multi-factor Analysis:\n",
    "\n",
    "- Coefficients: [38.24, 0.57, -0.46, -0.21]\n",
    "\n",
    "- Intercept: 3.75\n",
    "\n",
    "This indicates that multiple factors influence the days to resolve, with varying degrees of impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices most likely to fail soon:\n",
      "                   product_key            device_model  device_age  \\\n",
      "8             100005651-502245           LUNAR HALO 3D         4.0   \n",
      "7396  6680313-M6679638S1501264  TRIDENT SPECTRA VISION         2.0   \n",
      "7397  6680313-M6679638S1501265  TRIDENT SPECTRA VISION         2.0   \n",
      "7398  6680313-M6679638S1501267  TRIDENT SPECTRA VISION         2.0   \n",
      "7399  6680313-M6679638S1501268  TRIDENT SPECTRA VISION         2.0   \n",
      "7402  6680313-M6679638S1501272  TRIDENT SPECTRA VISION         2.0   \n",
      "7403  6680313-M6679638S1501274  TRIDENT SPECTRA VISION         2.0   \n",
      "7404  6680313-M6679638S1501277  TRIDENT SPECTRA VISION         2.0   \n",
      "7405  6680313-M6679638S1501278  TRIDENT SPECTRA VISION         2.0   \n",
      "7406  6680313-M6679638S1501279  TRIDENT SPECTRA VISION         2.0   \n",
      "\n",
      "      predicted_risk  predicted_time_to_failure  \n",
      "8           0.882502                        0.0  \n",
      "7396        0.999966                        0.0  \n",
      "7397        0.999996                        0.0  \n",
      "7398        0.999998                        0.0  \n",
      "7399        0.999988                        0.0  \n",
      "7402        0.999733                        0.0  \n",
      "7403        0.999999                        0.0  \n",
      "7404        1.000000                        0.0  \n",
      "7405        0.997977                        0.0  \n",
      "7406        1.000000                        0.0  \n",
      "\n",
      "Devices most likely to have multiple tickets in the next 90 days:\n",
      "                   product_key            device_model  device_age  \\\n",
      "2899            6464999-500547    OMEGA PRISM 3D 11X10         7.0   \n",
      "7433  6680313-M6679638S1501324  TRIDENT SPECTRA VISION         2.0   \n",
      "3116            6464999-500954    OMEGA PRISM 3D 11X10         7.0   \n",
      "3729            6464999-502235    OMEGA PRISM 3D 11X10         4.0   \n",
      "1973           6431659-3630630         VORTEX NEXUS 3D         8.0   \n",
      "3112            6464999-500948    OMEGA PRISM 3D 11X10         6.0   \n",
      "3731            6464999-502239    OMEGA PRISM 3D 11X10         5.0   \n",
      "419             6300011-629518         VORTEX NEXUS 3D        11.0   \n",
      "2834            6464999-500459    OMEGA PRISM 3D 11X10         7.0   \n",
      "2832            6464999-500454    OMEGA PRISM 3D 11X10         7.0   \n",
      "\n",
      "      multiple_ticket_probability  \n",
      "2899                          1.0  \n",
      "7433                          1.0  \n",
      "3116                          1.0  \n",
      "3729                          1.0  \n",
      "1973                          1.0  \n",
      "3112                          1.0  \n",
      "3731                          1.0  \n",
      "419                           1.0  \n",
      "2834                          1.0  \n",
      "2832                          1.0  \n",
      "\n",
      "Results saved to device_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Run the main analysis\n",
    "results, survival_model, ticket_model = main(df)\n",
    "\n",
    "# Display results\n",
    "print(\"Devices most likely to fail soon:\")\n",
    "high_risk = results[results['predicted_risk'] > 0.7].sort_values('predicted_time_to_failure')\n",
    "print(high_risk[['product_key', 'device_model', 'device_age', 'predicted_risk', 'predicted_time_to_failure']].head(10))\n",
    "\n",
    "print(\"\\nDevices most likely to have multiple tickets in the next 90 days:\")\n",
    "high_ticket_risk = results[results['multiple_ticket_probability'] > 0.7].sort_values('multiple_ticket_probability', ascending=False)\n",
    "print(high_ticket_risk[['product_key', 'device_model', 'device_age', 'multiple_ticket_probability']].head(10))\n",
    "\n",
    "# Save results to CSV\n",
    "results.to_csv('device_predictions.csv', index=False)\n",
    "\n",
    "print(\"\\nResults saved to device_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devices Most Likely to Fail Soon\n",
    "1. LUNAR HALO 3D (product_key: 100005651-502245)\n",
    "\n",
    "- Device age: 4 years\n",
    "\n",
    "- Predicted risk: 88.25%\n",
    "\n",
    "- Predicted time to failure: 0 days\n",
    "\n",
    "TRIDENT SPECTRA VISION (multiple devices)\n",
    "\n",
    "- Device age: 2 years\n",
    "\n",
    "- Predicted risk: 99.73% - 100%\n",
    "\n",
    "- Predicted time to failure: 0 days\n",
    "\n",
    "These devices show a very high predicted risk of failure, with the TRIDENT SPECTRA VISION models having an almost certain chance of failure. The predicted time to failure of 0 days suggests that these devices may have already failed or are on the verge of failing.\n",
    "\n",
    "Devices Most Likely to Have Multiple Tickets in the Next 90 Days\n",
    "1. OMEGA PRISM 3D 11X10 (multiple devices)\n",
    "\n",
    "- Device age: 4-7 years\n",
    "\n",
    "- Multiple ticket probability: 100%\n",
    "\n",
    "2. TRIDENT SPECTRA VISION (product_key: 6680313-M6679638S1501324)\n",
    "\n",
    "- Device age: 2 years\n",
    "\n",
    "- Multiple ticket probability: 100%\n",
    "\n",
    "3. VORTEX NEXUS 3D (multiple devices)\n",
    "\n",
    "- Device age: 8-11 years\n",
    "\n",
    "- Multiple ticket probability: 100%\n",
    "\n",
    "These devices all have a 100% probability of generating multiple tickets in the next 90 days, indicating potential ongoing issues or maintenance requirements.\n",
    "\n",
    "Key Observations\n",
    "1. The TRIDENT SPECTRA VISION model appears in both lists, suggesting it may be prone to both failures and frequent service requests.\n",
    "\n",
    "2. Older devices (OMEGA PRISM 3D 11X10 and VORTEX NEXUS 3D) are more likely to generate multiple tickets, possibly due to wear and tear or outdated technology.\n",
    "\n",
    "3. The LUNAR HALO 3D, despite being relatively young (4 years), has a high failure risk, which may indicate a potential design flaw or manufacturing issue.\n",
    "\n",
    "4. There's a correlation between device age and the likelihood of generating multiple tickets, but not necessarily with the risk of immediate failure.\n",
    "\n",
    "These insights can be used to prioritize preventive maintenance, plan for potential replacements, and allocate support resources more effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
